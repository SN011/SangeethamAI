{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jQI4U7A1h34o",
    "outputId": "ed7d147f-4eaf-4cda-ca82-0fe6c48c1f01"
   },
   "outputs": [],
   "source": [
    "FPS = 30\n",
    "FFT_WINDOW_SECONDS = 0.25 # how many seconds of audio make up an FFT window\n",
    "\n",
    "# Note range to display\n",
    "FREQ_MIN = 10\n",
    "FREQ_MAX = 1000\n",
    "\n",
    "# Notes to display\n",
    "TOP_NOTES = 3\n",
    "\n",
    "# Names of the notes\n",
    "NOTE_NAMES = [\"C\", \"C#\", \"D\", \"D#\", \"E\", \"F\", \"F#\", \"G\", \"G#\", \"A\", \"A#\", \"B\"]\n",
    "\n",
    "# Output size. Generally use SCALE for higher res, unless you need a non-standard aspect ratio.\n",
    "RESOLUTION = (1920, 1080)\n",
    "SCALE = 2 # 0.5=QHD(960x540), 1=HD(1920x1080), 2=4K(3840x2160)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !ffmpeg -i muthai_tharu_slow.wav -filter:a \"atempo=0.5\" muthai_tharu_slow2.wav\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9eOd8Tm-jIW5",
    "outputId": "35c9b414-3e56-46fd-db62-79712144f834"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from scipy.fftpack import fft\n",
    "from scipy.io import wavfile # get the api\n",
    "import os\n",
    "\n",
    "\n",
    "AUDIO_FILE = \"muthai_tharu_slow2.wav\"\n",
    "\n",
    "fs, data = wavfile.read(AUDIO_FILE) # load the data\n",
    "audio = data.T[0] # this is a two channel soundtrack, get the first track\n",
    "FRAME_STEP = (fs / FPS) # audio samples per video frame\n",
    "FFT_WINDOW_SIZE = int(fs * FFT_WINDOW_SECONDS)\n",
    "AUDIO_LENGTH = len(audio)/fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "i7OinuERiRak",
    "outputId": "35b808a3-c53c-4463-9e41-ac14dfc3ffc6"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "# See https://newt.phys.unsw.edu.au/jw/notes.html\n",
    "def freq_to_number(f): return 69 + 12*np.log2(f/440.0)\n",
    "def number_to_freq(n): return 440 * 2.0**((n-69)/12.0)\n",
    "def note_name(n): return NOTE_NAMES[n % 12] + str(int(n/12 - 1))\n",
    "\n",
    "# Hanning window function\n",
    "window = 0.5 * (1 - np.cos(np.linspace(0, 2*np.pi, FFT_WINDOW_SIZE, False)))\n",
    "\n",
    "xf = np.fft.rfftfreq(FFT_WINDOW_SIZE, 1/fs)\n",
    "FRAME_COUNT = int(AUDIO_LENGTH*FPS)\n",
    "FRAME_OFFSET = int(len(audio)/FRAME_COUNT)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "def plot_fft(p, xf, fs, notes, dimensions=(960,540)):\n",
    "  layout = go.Layout(\n",
    "      title=\"frequency spectrum\",\n",
    "      autosize=False,\n",
    "      width=dimensions[0],\n",
    "      height=dimensions[1],\n",
    "      xaxis_title=\"Frequency (note)\",\n",
    "      yaxis_title=\"Magnitude\",\n",
    "      font={'size' : 24}\n",
    "  )\n",
    "\n",
    "  fig = go.Figure(layout=layout,\n",
    "                  layout_xaxis_range=[FREQ_MIN,FREQ_MAX],\n",
    "                  layout_yaxis_range=[0,1]\n",
    "                  )\n",
    "  \n",
    "  fig.add_trace(go.Scatter(\n",
    "      x = xf,\n",
    "      y = p))\n",
    "  \n",
    "  for note in notes:\n",
    "    fig.add_annotation(x=note[0]+10, y=note[2],\n",
    "            text=note[1],\n",
    "            font = {'size' : 48},\n",
    "            showarrow=False)\n",
    "  return fig\n",
    "\n",
    "def extract_sample(audio, frame_number):\n",
    "  end = frame_number * FRAME_OFFSET\n",
    "  begin = int(end - FFT_WINDOW_SIZE)\n",
    "\n",
    "  if end == 0:\n",
    "    # We have no audio yet, return all zeros (very beginning)\n",
    "    return np.zeros((np.abs(begin)),dtype=float)\n",
    "  elif begin<0:\n",
    "    # We have some audio, padd with zeros\n",
    "    return np.concatenate([np.zeros((np.abs(begin)),dtype=float),audio[0:end]])\n",
    "  else:\n",
    "    # Usually this happens, return the next sample\n",
    "    return audio[begin:end]\n",
    "\n",
    "def find_top_notes(fft,num):\n",
    "  if np.max(fft.real)<0.001:\n",
    "    return []\n",
    "\n",
    "  lst = [x for x in enumerate(fft.real)]\n",
    "  lst = sorted(lst, key=lambda x: x[1],reverse=True)\n",
    "\n",
    "  idx = 0\n",
    "  found = []\n",
    "  found_note = set()\n",
    "  while( (idx<len(lst)) and (len(found)<num) ):\n",
    "    f = xf[lst[idx][0]]\n",
    "    y = lst[idx][1]\n",
    "    n = freq_to_number(f)\n",
    "    n0 = int(round(n))\n",
    "    name = note_name(n0)\n",
    "\n",
    "    if name not in found_note:\n",
    "      found_note.add(name)\n",
    "      s = [f,note_name(n0),y]\n",
    "      found.append(s)\n",
    "    idx += 1\n",
    "    \n",
    "  return found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max amplitude: 54067799.11678628\n"
     ]
    }
   ],
   "source": [
    "# Pass 1, find out the maximum amplitude so we can scale.\n",
    "mx = 0\n",
    "for frame_number in range(FRAME_COUNT):\n",
    "  sample = extract_sample(audio, frame_number)\n",
    "\n",
    "  fft = np.fft.rfft(sample * window)\n",
    "  fft = np.abs(fft).real \n",
    "  mx = max(np.max(fft),mx)\n",
    "\n",
    "print(f\"Max amplitude: {mx}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Mandra': {'Sa': 164.81,\n",
       "  'Ri2': 185.41125,\n",
       "  'Ga1': 206.0125,\n",
       "  'Ma2': 219.74666666666667,\n",
       "  'Pa': 247.215,\n",
       "  'Da1': 263.696,\n",
       "  'Ni1': 296.658,\n",
       "  'Sa_high': 329.62},\n",
       " 'Madhya': {'Sa': 329.63,\n",
       "  'Ri2': 370.83375,\n",
       "  'Ga1': 412.0375,\n",
       "  'Ma2': 439.50666666666666,\n",
       "  'Pa': 494.445,\n",
       "  'Da1': 527.408,\n",
       "  'Ni1': 593.3340000000001,\n",
       "  'Sa_high': 659.26},\n",
       " 'Taara': {'Sa': 659.25,\n",
       "  'Ri2': 741.65625,\n",
       "  'Ga1': 824.0625,\n",
       "  'Ma2': 879.0,\n",
       "  'Pa': 988.875,\n",
       "  'Da1': 1054.8,\n",
       "  'Ni1': 1186.65,\n",
       "  'Sa_high': 1318.5}}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define reference frequencies for Sa in each octave\n",
    "LOW_SA_FREQ = 164.81  # Sa in Mandra octave (E3 in Hz)\n",
    "MIDDLE_SA_FREQ = 329.63  # Sa in Madhya octave (E4 in Hz)\n",
    "HIGH_SA_FREQ = 659.25  # Sa in Taara octave (E5 in Hz)\n",
    "\n",
    "# Define swara ratios relative to Sa (using ratios specific to Shanmukhapriya scale)\n",
    "RATIOS = {\n",
    "    'Sa': 1,\n",
    "    'Ri2': 9/8,\n",
    "    'Ga1': 5/4,\n",
    "    'Ma2': 4/3,\n",
    "    'Pa': 3/2,\n",
    "    'Da1': 8/5,\n",
    "    'Ni1': 9/5,\n",
    "    'Sa_high': 2  # Sa in the higher octave\n",
    "}\n",
    "\n",
    "# Function to calculate frequencies for each swara in all octaves\n",
    "def calculate_swara_frequencies(base_freq):\n",
    "    return {s: base_freq * ratio for s, ratio in RATIOS.items()}\n",
    "\n",
    "# Calculate frequencies for each octave\n",
    "mandra_frequencies = calculate_swara_frequencies(LOW_SA_FREQ)\n",
    "madhya_frequencies = calculate_swara_frequencies(MIDDLE_SA_FREQ)\n",
    "taara_frequencies = calculate_swara_frequencies(HIGH_SA_FREQ)\n",
    "\n",
    "# Combine results\n",
    "all_frequencies = {\n",
    "    'Mandra': mandra_frequencies,\n",
    "    'Madhya': madhya_frequencies,\n",
    "    'Taara': taara_frequencies\n",
    "}\n",
    "\n",
    "# Display all frequencies\n",
    "all_frequencies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def freq_to_swara(frequency):\n",
    "    \"\"\"\n",
    "    Map a frequency to the nearest Carnatic swara across all octaves.\n",
    "    \n",
    "    Parameters:\n",
    "        frequency (float): The frequency in Hz to map.\n",
    "        \n",
    "    Returns:\n",
    "        str: The corresponding swara name with octave or None if no match is found.\n",
    "    \"\"\"\n",
    "    if frequency == 0:\n",
    "        return None\n",
    "\n",
    "    min_diff = float('inf')\n",
    "    closest_swara = None\n",
    "    \n",
    "    # Iterate through each octave in all_frequencies\n",
    "    for octave, swaras in all_frequencies.items():\n",
    "        for swara, freq in swaras.items():\n",
    "            diff = abs(frequency - freq)\n",
    "            if diff < min_diff:\n",
    "                min_diff = diff\n",
    "                closest_swara = f\"{swara} ({octave})\"\n",
    "    \n",
    "    # Define a tolerance level (e.g., within 30 Hz)\n",
    "    TOLERANCE = 30\n",
    "    if min_diff <= TOLERANCE:\n",
    "        return closest_swara\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def detect_swaras(audio_path, output_txt_path, sr=None, hop_length=512, n_fft=2048):\n",
    "    \"\"\"\n",
    "    Detect swaras from an audio file and write them to a text file.\n",
    "    \n",
    "    Parameters:\n",
    "        audio_path (str): Path to the input audio file.\n",
    "        output_txt_path (str): Path to the output text file.\n",
    "        sr (int, optional): Sampling rate. If None, uses the file's original rate.\n",
    "        hop_length (int, optional): Number of samples between successive frames.\n",
    "        n_fft (int, optional): Length of the FFT window.\n",
    "    \"\"\"\n",
    "    # Load audio file\n",
    "    print(\"Loading audio file...\")\n",
    "    audio, sr = librosa.load(audio_path, sr=sr, mono=True)\n",
    "    print(f\"Audio loaded. Duration: {librosa.get_duration(y=audio, sr=sr):.2f} seconds.\")\n",
    "    \n",
    "    # Normalize audio\n",
    "    audio = audio / np.max(np.abs(audio))\n",
    "    \n",
    "    # Perform pitch tracking\n",
    "    print(\"Performing pitch detection...\")\n",
    "    pitches, magnitudes = librosa.piptrack(y=audio, sr=sr, hop_length=hop_length, n_fft=n_fft)\n",
    "    \n",
    "    # Initialize list to store detected swaras\n",
    "    detected_swaras = []\n",
    "    \n",
    "    # Iterate through each frame\n",
    "    print(\"Mapping frequencies to swaras...\")\n",
    "    for i in tqdm.tqdm(range(pitches.shape[1])):\n",
    "        index = magnitudes[:, i].argmax()\n",
    "        pitch = pitches[index, i]\n",
    "        if pitch > 0:\n",
    "            swara = freq_to_swara(pitch)\n",
    "            if swara:\n",
    "                detected_swaras.append(swara)\n",
    "            else:\n",
    "                detected_swaras.append('---')  # Placeholder for no match\n",
    "        else:\n",
    "            detected_swaras.append('---')  # Placeholder for no pitch detected\n",
    "    \n",
    "    # Write swaras to text file\n",
    "    print(f\"Writing detected swaras to {output_txt_path}...\")\n",
    "    with open(output_txt_path, 'w') as f:\n",
    "        for swara in detected_swaras:\n",
    "            f.write(swara + ' ')\n",
    "    print(\"Swara detection and writing completed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading audio file...\n",
      "Audio loaded. Duration: 524.32 seconds.\n",
      "Performing pitch detection...\n",
      "Mapping frequencies to swaras...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49155/49155 [00:01<00:00, 33542.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing detected swaras to music_notes_swaras.txt...\n",
      "Swara detection and writing completed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Define paths\n",
    "    AUDIO_FILE = \"muthai_tharu_slow2.wav\"  # Replace with your audio file path\n",
    "    OUTPUT_TXT = \"music_notes_swaras.txt\"  # Output text file path\n",
    "    \n",
    "    # Detect swaras and write to text file\n",
    "    detect_swaras(AUDIO_FILE, OUTPUT_TXT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tqdm\n",
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt  # Using matplotlib for efficiency\n",
    "# import os\n",
    "\n",
    "# # Ensure the output directory exists\n",
    "# output_dir = \"C:\\\\DEV\\\\SangeethamAI\\\\content\"\n",
    "# os.makedirs(output_dir, exist_ok=True)\n",
    "# with open('music_notes.txt', 'w+') as musicfile:\n",
    "\n",
    "#     # Pass 2, produce the animation\n",
    "#     for frame_number in tqdm.tqdm(range(FRAME_COUNT)):\n",
    "#         #print(f\"Processing frame {frame_number + 1}/{FRAME_COUNT}\")  # Debug print\n",
    "\n",
    "#         # Extract the sample\n",
    "#         sample = extract_sample(audio, frame_number)\n",
    "\n",
    "#         # Compute FFT\n",
    "#         fft = np.fft.rfft(sample * window)\n",
    "#         fft = np.abs(fft) / mx \n",
    "\n",
    "#         # Find top notes\n",
    "#         s = find_top_notes(fft, 4)\n",
    "\n",
    "#         # Plot FFT using matplotlib for faster rendering\n",
    "#         plt.figure()\n",
    "#         plt.plot(xf, fft.real)  # Assuming `xf` and `fft` dimensions match\n",
    "#         plt.title(f\"FFT Frame {frame_number}\")\n",
    "#         plt.xlabel('Frequency (Hz)')\n",
    "#         plt.ylabel('Amplitude')\n",
    "#         plt.ylim(0,1)\n",
    "#         plt.xlim(0,1000)\n",
    "\n",
    "#         # Annotate the top notes on the FFT plot\n",
    "#         for note in s:\n",
    "#             frequency, note_label, magnitude = note\n",
    "#             #note_label = western_to_carnatic[note_label[:-1]]\n",
    "#             plt.annotate(note_label, \n",
    "#                         xy=(frequency, magnitude), \n",
    "#                         xytext=(frequency + 10, magnitude + 0.05), \n",
    "#                         fontsize=9, color='red', \n",
    "#                         arrowprops=dict(arrowstyle=\"->\", color='red'))\n",
    "#             musicfile.write(note_label + \" \")\n",
    "#         # # Save the frame\n",
    "#         frame_path = os.path.join(output_dir, f\"frame{frame_number}.png\")\n",
    "#         plt.savefig(frame_path, dpi=100)  # Lower DPI for faster saving\n",
    "#         plt.close()  # Close the figure to release memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LzPw9WT-Lfmy",
    "outputId": "902b4759-c184-44e5-c009-a7f8b15f6ea5"
   },
   "outputs": [],
   "source": [
    "# !ffmpeg -y -r {FPS} -f image2 -s 1920x1080 -i content/frame%d.png -i {AUDIO_FILE} -c:v libx264 -c:a aac -pix_fmt yuv420p -shortest movie.mp4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "TheVirtualEnv",
   "language": "python",
   "name": "thevirtualenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
